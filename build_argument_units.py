import os, re, json, time
from openai import OpenAI
from qdrant_client import QdrantClient

# üîß Setup logging
def log(msg):
    print(f"[{time.strftime('%H:%M:%S')}] {msg}", flush=True)

# --- main process ---
def build_argument_units(input_path):
    log("üöÄ Starting jyotir-app argument unit builder")

    if not os.path.exists(input_path):
        log(f"‚ùå Input file not found: {input_path}")
        return

    with open(input_path, "r", encoding="utf-8") as f:
        text = f.read()

    log(f"üìÑ Loaded {len(text.split())} words from {input_path}")

    # Example placeholder: detect title, etc.
    title = "Detected Lecture Title"
    class_num = 5
    log(f"üéì Processing: {title} (Class {class_num})")

    structured_text = [{"segment": "example"}]  # ‚Üê Replace with your generation step
    output_file = f"class_{class_num}_{re.sub(r'[^A-Za-z0-9_]+', '_', title)}.json"

    os.makedirs("Data", exist_ok=True)
    out_path = os.path.join("Data", output_file)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(structured_text, f, ensure_ascii=False, indent=2)

    log(f"üíæ Saved structured data ‚Üí {out_path}")
    return out_path

# --- end script ---
if __name__ == "__main__":
    INPUT_FILE = "pasted.txt"
    log("‚úÖ Script started")
    result = build_argument_units(INPUT_FILE)
    if result:
        log("üèÅ Processing complete. Going idle.")
    else:
        log("‚ö†Ô∏è Nothing processed. Exiting early.")
    time.sleep(3600)


import time
print("‚úÖ Task complete. Sleeping to keep Render happy...")
time.sleep(3600)  # Keeps the worker alive for 1 hour
import os
import re
import json
from datetime import datetime
from openai import OpenAI
from qdrant_client import QdrantClient
from sentence_transformers import SentenceTransformer

# ==========================
# CONFIGURATION
# ==========================
INPUT_FILE = "pasted.txt"
OUTPUT_DIR = "Data"

GPT_MODEL = os.getenv("GPT_MODEL", "gpt-5.2")  # reasoning model
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "all-MiniLM-L6-v2")  # for Qdrant
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

import os
from openai import OpenAI

# --- Debug check for Render environment ---
key = os.getenv("OPENAI_API_KEY")
if not key:
    print("‚ùå No OPENAI_API_KEY found in environment!")
else:
    print("‚úÖ OPENAI_API_KEY detected (starts with):", key[:8])

client = OpenAI(api_key=key)

# ==========================
# HELPERS
# ==========================
def log(msg: str):
    print(f"ü™∂ {msg}")

def detect_class_info(text):
    """Extract lecture title and class number from the pasted text."""
    match = re.search(r'Class\s*(\d+)', text)
    class_num = match.group(1) if match else "unknown"
    title_line = text.strip().splitlines()[0] if text.strip() else "Untitled"
    return title_line.strip(), class_num

def generate_argument_units(text):
    """Use GPT model to segment the lecture into structured units."""
    log("üéØ Generating structured text with GPT model...")
    prompt = f"""
    Segment the following Vedanta lecture text into structured argument units.
    Each unit should include: Topic, Shabda pivot, Purvapaksha, Siddhanta, and Quotation.

    Lecture:
    {text}
    """
    response = client.chat.completions.create(
        model=GPT_MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()

def embed_and_upload_to_qdrant(title, class_num, text):
    """Generate embeddings and upload to Qdrant memory."""
    log("üß† Uploading structured knowledge to Qdrant memory...")
    model = SentenceTransformer(EMBEDDING_MODEL)
    embeddings = model.encode([text])
    collection_name = "jyotir_bramana_memory"

    qdrant = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
    qdrant.recreate_collection(
        collection_name=collection_name,
        vectors_config={"size": len(embeddings[0]), "distance": "Cosine"}
    )
    qdrant.upsert(
        collection_name=collection_name,
        points=[{
            "id": int(datetime.now().timestamp()),
            "vector": embeddings[0],
            "payload": {
                "title": title,
                "class_num": class_num,
                "content": text
            }
        }]
    )
    log("‚úÖ Uploaded to Qdrant successfully.")

# ==========================
# CORE LOGIC
# ==========================
def build_argument_units(input_path: str):
    """Main process: read text, segment, save JSON, and upload to Qdrant."""
    if not os.path.exists(input_path):
        raise FileNotFoundError(f"Input file not found: {input_path}")

    log(f"üìñ Processing {input_path} ‚Äì please wait...")

    with open(input_path, "r", encoding="utf-8") as f:
        text = f.read()

    title, class_num = detect_class_info(text)
    log(f"üìò Detected lecture: {title}")

    structured_text = generate_argument_units(text)

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    safe_title = re.sub(r"[^A-Za-z0-9_]+", "_", title)
    output_file = os.path.join(OUTPUT_DIR, f"class_{class_num}_{safe_title}.json")

    result = {
        "title": title,
        "class_num": class_num,
        "content": structured_text
}

if __name__ == "__main__":
    build_argument_units(INPUT_FILE)

    print("‚úÖ Task complete. Sleeping to keep Render happy...")
    import time
    time.sleep(3600)  # Keep alive for 1 hour


